{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ffd336",
   "metadata": {},
   "source": [
    "## ***Load the Document***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3b7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "file_path = \"./deepLearning-book/d2l-en.pdf\"\n",
    "loader = PyPDFLoader(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf26446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1151"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1921f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 Environment and Distribution Shift\n",
      "parametrized function), it follows that\n",
      "ğ›½ğ‘– = 1ÂÂ¹1 Â¸expÂ¹\u0000â„Â¹xğ‘–ÂºÂºÂº\n",
      "expÂ¹\u0000â„Â¹xğ‘–ÂºÂºÂÂ¹1 Â¸expÂ¹\u0000â„Â¹xğ‘–ÂºÂºÂº = expÂ¹â„Â¹xğ‘–ÂºÂº. (4.7.7)\n",
      "As a result, we need to solve two problems: the first, to distinguish between data drawn\n",
      "frombothdistributions,andthenaweightedempiricalriskminimizationproblemin (4.7.5)\n",
      "where we weigh terms byğ›½ğ‘–.\n",
      "Now we are ready to describe a correction algorithm. Suppose that we have a training set\n",
      "fÂ¹x1,ğ‘¦1Âº,..., Â¹xğ‘›,ğ‘¦ğ‘›Âºgand an unlabeled test setfu1,..., uğ‘šg. For covariate shift, we\n",
      "assume thatxğ‘– for all1 \u0014ğ‘– \u0014ğ‘›are drawn from some source distribution anduğ‘– for all\n",
      "1 \u0014ğ‘– \u0014ğ‘š are drawn from the target distribution. Here is a prototypical algorithm for\n",
      "correcting covariate shift:\n",
      "1. Createabinary-classificationtrainingset: fÂ¹x1,\u00001Âº,..., Â¹xğ‘›,\u00001Âº,Â¹u1,1Âº,..., Â¹uğ‘š,1Âºg.\n",
      "2. Train a binary classifier using logistic regression to get the functionâ„.\n",
      "3. Weigh training data usingğ›½ğ‘– = expÂ¹â„Â¹xğ‘–ÂºÂºor betterğ›½ğ‘– = minÂ¹expÂ¹â„Â¹xğ‘–ÂºÂº,ğ‘Âºfor some\n",
      "constant ğ‘.\n",
      "4. Use weightsğ›½ğ‘– for training onfÂ¹x1,ğ‘¦1Âº,..., Â¹xğ‘›,ğ‘¦ğ‘›Âºgin (4.7.5).\n",
      "Note that the above algorithm relies on a crucial assumption. For this scheme to work, we\n",
      "need that each data example in the target (e.g., test time) distribution had nonzero proba-\n",
      "bility of occurring at training time. If we find a point whereğ‘Â¹xÂº> 0 but ğ‘Â¹xÂº= 0, then\n",
      "the corresponding importance weight should be infinity.\n",
      "Label Shift Correction\n",
      "Assume that we are dealing with a classification task withğ‘˜ categories. Using the same\n",
      "notation inSection 4.7.3, ğ‘and ğ‘are the source distribution (e.g., training time) and target\n",
      "distribution (e.g., test time), respectively. Assume that the distribution of labels shifts over\n",
      "time: ğ‘Â¹ğ‘¦Âºâ‰  ğ‘Â¹ğ‘¦Âº, but the class-conditional distribution stays the same:ğ‘Â¹x jğ‘¦Âº= ğ‘Â¹x j\n",
      "ğ‘¦Âº. If the source distribution ğ‘Â¹ğ‘¦Âºis â€œwrongâ€, we can correct for that according to the\n",
      "following identity in the risk as defined in(4.7.2):\n",
      "Â¹ Â¹\n",
      "ğ‘™Â¹ğ‘“Â¹xÂº,ğ‘¦Âºğ‘Â¹x jğ‘¦Âºğ‘Â¹ğ‘¦Âºğ‘‘xğ‘‘ğ‘¦ =\n",
      "Â¹ Â¹\n",
      "ğ‘™Â¹ğ‘“Â¹xÂº,ğ‘¦Âºğ‘Â¹x jğ‘¦Âºğ‘Â¹ğ‘¦Âºğ‘Â¹ğ‘¦Âº\n",
      "ğ‘Â¹ğ‘¦Âºğ‘‘xğ‘‘ğ‘¦.\n",
      "(4.7.8)\n",
      "Here, our importance weights will correspond to the label likelihood ratios:\n",
      "ğ›½ğ‘–\n",
      "def\n",
      "= ğ‘Â¹ğ‘¦ğ‘–Âº\n",
      "ğ‘Â¹ğ‘¦ğ‘–Âº. (4.7.9)\n",
      "One nice thing about label shift is that if we have a reasonably good model on the source\n",
      "distribution, then we can get consistent estimates of these weights without ever having to\n",
      "deal with the ambient dimension. In deep learning, the inputs tend to be high-dimensional\n",
      "objects like images, while the labels are often simpler objects like categories.\n",
      "To estimate the target label distribution, we first take our reasonably good off-the-shelf\n"
     ]
    }
   ],
   "source": [
    "print(docs[200].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4831fd5",
   "metadata": {},
   "source": [
    "## **Semantic Chunking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd7aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
